{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "final_year_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemanthk1099/final_year_project/blob/main/final_year_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9UcZ5gNvt-b",
        "outputId": "69e27c95-73b7-4d65-9a42-68285f5c4c2a"
      },
      "source": [
        "!pip install pyfpgrowth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyfpgrowth in /usr/local/lib/python3.7/dist-packages (1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9fp9beyk-LQL",
        "outputId": "5b37f551-8d7f-4f06-9aba-5959d0fd71b0"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGh9hziJbCVr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import jaccard_score\n",
        "from pandas import DataFrame\n",
        "import pyfpgrowth\n",
        "import datetime\n",
        "# from fp_growth import find_frequent_itemsets\n",
        "# from mlxtend.frequent_patterns import fpgrowth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-fGAXei9PQy"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/final_year_project/Market_Basket_Optimisation.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1UPolMQCJZv9",
        "outputId": "1972ea10-d622-443b-9d04-8ed028bc7f39"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shrimp</th>\n",
              "      <th>almonds</th>\n",
              "      <th>avocado</th>\n",
              "      <th>vegetables mix</th>\n",
              "      <th>green grapes</th>\n",
              "      <th>whole weat flour</th>\n",
              "      <th>yams</th>\n",
              "      <th>cottage cheese</th>\n",
              "      <th>energy drink</th>\n",
              "      <th>tomato juice</th>\n",
              "      <th>low fat yogurt</th>\n",
              "      <th>green tea</th>\n",
              "      <th>honey</th>\n",
              "      <th>salad</th>\n",
              "      <th>mineral water</th>\n",
              "      <th>salmon</th>\n",
              "      <th>antioxydant juice</th>\n",
              "      <th>frozen smoothie</th>\n",
              "      <th>spinach</th>\n",
              "      <th>olive oil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>burgers</td>\n",
              "      <td>meatballs</td>\n",
              "      <td>eggs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chutney</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>turkey</td>\n",
              "      <td>avocado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mineral water</td>\n",
              "      <td>milk</td>\n",
              "      <td>energy bar</td>\n",
              "      <td>whole wheat rice</td>\n",
              "      <td>green tea</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>low fat yogurt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           shrimp    almonds     avocado  ... frozen smoothie spinach olive oil\n",
              "0         burgers  meatballs        eggs  ...             NaN     NaN       NaN\n",
              "1         chutney        NaN         NaN  ...             NaN     NaN       NaN\n",
              "2          turkey    avocado         NaN  ...             NaN     NaN       NaN\n",
              "3   mineral water       milk  energy bar  ...             NaN     NaN       NaN\n",
              "4  low fat yogurt        NaN         NaN  ...             NaN     NaN       NaN\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwdGdltfFf41",
        "outputId": "4861e97d-4676-47ab-ee58-edb7408632a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4aZcMrtJbra"
      },
      "source": [
        "data_array = np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY5VSJEbMuxN",
        "outputId": "22126b6a-f528-4088-96de-a2bb3b9c20fd"
      },
      "source": [
        "data_array[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['burgers', 'meatballs', 'eggs', nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
              "       ['chutney', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan, nan, nan, nan],\n",
              "       ['turkey', 'avocado', nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
              "       ['mineral water', 'milk', 'energy bar', 'whole wheat rice',\n",
              "        'green tea', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan],\n",
              "       ['low fat yogurt', nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWTkvhcX9GuH"
      },
      "source": [
        "def preprocess1(data_array):\n",
        "  org_data = dict()\n",
        "  org_data_list = list()\n",
        "  for test_list in data_array:\n",
        "    res = []\n",
        "    for val in test_list:\n",
        "        if str(val) != 'nan':\n",
        "            res.append(val)\n",
        "    res.sort()\n",
        "    org_data_list.append(res)\n",
        "    org_data_list.sort(key = len , reverse=True)\n",
        "    i = 0\n",
        "    for trans in org_data_list:\n",
        "      org_data[i] = trans\n",
        "      i += 1\n",
        "  return org_data , org_data_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8QdqUEpc8IQ"
      },
      "source": [
        "# org_data_list list of transactions sorted in descending order\n",
        "# org_data dictionary of transactions - key is transaction id\n",
        "org_data , org_data_list = preprocess1(data_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AIPxkHG4MC3"
      },
      "source": [
        "#find freq table\n",
        "def find_freq_table(transactions):\n",
        "  freq_table = dict()\n",
        "  for transaction in transactions:\n",
        "    for item in transaction:\n",
        "      if item not in freq_table.keys():\n",
        "        freq_table[item] = 1\n",
        "      else:\n",
        "        freq_table[item] += 1\n",
        "  freq_table = {k: v for k, v in sorted(freq_table.items(), key=lambda item: item[1])}\n",
        "  return freq_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9jUPwu3-KzR"
      },
      "source": [
        "freq_table = find_freq_table(org_data.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeC0y7y45k0W"
      },
      "source": [
        "# generate item_id and id_item dict\n",
        "def id_item_dict(items):\n",
        "  i = 0\n",
        "  item_id = dict()\n",
        "  id_item = dict()\n",
        "  for item in items:\n",
        "    item_id[item] = i\n",
        "    id_item[i] = item\n",
        "    i += 1\n",
        "  return item_id , id_item"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjCHg0e352zV"
      },
      "source": [
        "item_id, id_item = id_item_dict(freq_table.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7xKLzgj6FZF"
      },
      "source": [
        "## find one hot encoding of the database\n",
        "def find_one_hot(data: dict, item_id: dict):\n",
        "  one_hot_dict = dict()\n",
        "  for key in data.keys():\n",
        "    one_hot = np.zeros(len(item_id))\n",
        "    for item in data[key]:\n",
        "      one_hot[item_id[item]] = 1\n",
        "    one_hot_dict[key] = one_hot\n",
        "  return one_hot_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T40_xtxjANKb"
      },
      "source": [
        "one_hot_dict = find_one_hot(org_data,item_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMfn3vpCBY2V"
      },
      "source": [
        "def jaccard_index(s1, s2) :\n",
        "      \n",
        "    # Sizes of both the sets \n",
        "    size_s1 = len(s1); \n",
        "    size_s2 = len(s2); \n",
        "  \n",
        "    # Get the intersection set \n",
        "    intersect = set(s1).intersection(set(s2)); \n",
        "  \n",
        "    # Size of the intersection set \n",
        "    size_in = len(intersect); \n",
        "  \n",
        "    # Calculate the Jaccard index \n",
        "    # using the formula \n",
        "    jaccard_in = size_in  / (size_s1 + size_s2 - size_in); \n",
        "  \n",
        "    # Return the Jaccard index \n",
        "    return 1-jaccard_in; "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L88Gt_HpBZm8",
        "outputId": "ca03fa11-c4c1-4fdc-f56b-8ba8e46e2da6"
      },
      "source": [
        "# set k no of clusters = no of unique items\n",
        "k = len(item_id)\n",
        "k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-18pT8gmwCLb"
      },
      "source": [
        "# compare function for calculation of centroids\n",
        "def compare(a , b):\n",
        "  for i in range(0,len(b)):\n",
        "    if b[i] == 1 and a[i] == 0:\n",
        "      return False\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZcRkCoWBZkr"
      },
      "source": [
        "# items is one-hot-encoded-transactions\n",
        "def find_k_centroids(items,k):\n",
        "  centroids = dict()\n",
        "  for key in items.keys():\n",
        "    if len(centroids) <k:\n",
        "      check = False\n",
        "      for centroid_key in centroids.keys():\n",
        "        if compare(centroids[centroid_key],items[key]):\n",
        "          check = True\n",
        "          break\n",
        "      if not check:\n",
        "        centroids[key] = items[key]\n",
        "  return centroids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPidfc1Gy0GS"
      },
      "source": [
        "centroids = find_k_centroids(one_hot_dict,k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zlDCVZjzinr"
      },
      "source": [
        "def get_centroids_with_id(centroids):\n",
        "  centroids_with_id = dict()\n",
        "  i =0\n",
        "  for centroid in centroids.values():\n",
        "    centroids_with_id[i] = centroid\n",
        "    i += 1\n",
        "  return centroids_with_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq1BuLmp5Wbo"
      },
      "source": [
        "centroids_with_id = get_centroids_with_id(centroids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJq1ZYaN2ymr"
      },
      "source": [
        "# returns a dict with key = transaction's key and value = cluster id which the item belongs to\n",
        "def cluster(centroids, items):\n",
        "  clusters_labels = dict()\n",
        "  for item_key in items.keys():\n",
        "    clusters_labels[item_key] = 0\n",
        "  for item_key in items.keys():\n",
        "    # closest_cluster = 0\n",
        "    min_dist = 1\n",
        "    for centroid_key in centroids.keys():\n",
        "      dist = jaccard_index(org_data_list[centroid_key],org_data_list[item_key])\n",
        "      if dist < min_dist:\n",
        "        min_dist = dist\n",
        "        clusters_labels[item_key] = centroid_key\n",
        "  return clusters_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpz6Qf_y3p6S"
      },
      "source": [
        "# clusters -dict of item_id-cluster_id , data - dict of item_id-transaction\n",
        "def prune_database(clusters, data, min_sup, number_of_clusters):\n",
        "  # count - number of items of a cluster - cluster_id - corresponding count \n",
        "  count = dict()\n",
        "  for i in range(0,number_of_clusters):\n",
        "    count[i] = 0\n",
        "  for i in clusters.keys():\n",
        "    count[clusters[i]] += 1\n",
        "\n",
        "  cluster_keys = set(count.keys())\n",
        "  # deleting cluster_ids with count < min_sup\n",
        "  for i in cluster_keys:\n",
        "      if count[i] < min_sup:\n",
        "        count.pop(i) \n",
        "  \n",
        "  # list\n",
        "  reduced_data = list()\n",
        "  \n",
        "  # set of cluster_ids after pruning\n",
        "  cluster_keys = set(count.keys())\n",
        "  \n",
        "  for i in data.keys():\n",
        "    if clusters[i] in cluster_keys:\n",
        "      reduced_data.append(data[i])\n",
        "    \n",
        "  return reduced_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKgWRiUKZ0JV"
      },
      "source": [
        "# data = dict\n",
        "def freq_pattern_with_clustering(centroids_with_id ,one_hot_dict,data,min_sup_count, k ):\n",
        "\n",
        "  t1 = datetime.datetime.now()\n",
        "  clusters = cluster(centroids_with_id,one_hot_dict)\n",
        "  pruning_parameter = 0.05\n",
        "  reduced_data = prune_database(clusters,data,int(min_sup_count*pruning_parameter),k)\n",
        "  t2 = datetime.datetime.now()\n",
        "  print(\"The dataset size reduced from \"+str(len(data))+\" to \"+str(len(reduced_data)))\n",
        "  print(\"time taken for clustering and pruning: \"+ str(t2-t1))\n",
        "\n",
        "  r = len(data) - len(reduced_data)\n",
        "\n",
        "  t2 = datetime.datetime.now()\n",
        "  min_support_count_for_reduced_dataset = int(min_sup_count*len(reduced_data)/len(data))\n",
        "  freq_itemsets = pyfpgrowth.find_frequent_patterns(reduced_data, min_support_count_for_reduced_dataset)\n",
        "  t3 = datetime.datetime.now()\n",
        "\n",
        "  print(\"time taken for fpgrowth with clustering: \"+ str(t3-t2))\n",
        "  # print(len(freq_itemsets))\n",
        "  # print(freq_itemsets)\n",
        "  return r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTggrliU7ysW"
      },
      "source": [
        "# data - array / list , min_sup -int\n",
        "def frequent_pattern_generation (data , min_sup_count):\n",
        "  a = datetime.datetime.now()\n",
        "  freq_itemsets = pyfpgrowth.find_frequent_patterns(data, min_sup_count)\n",
        "  b = datetime.datetime.now()\n",
        "  print(\"Time taken by fpgrowth without clustering :\"+ str(b-a))\n",
        "  # print(len(freq_itemsets))\n",
        "  # print(freq_itemsets)\n",
        "  return freq_itemsets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4I0wjlAaca2",
        "outputId": "8e0663b8-3f34-4194-8b67-cca7761cec5f"
      },
      "source": [
        "for min_sup_count in range(100,1500,100):\n",
        "  print(\"for min_sup = \"+str(min_sup_count))\n",
        "  r = freq_pattern_with_clustering(centroids_with_id, one_hot_dict, org_data, min_sup_count, k)\n",
        "  frequent_pattern_generation(org_data.values() , min_sup_count)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for min_sup = 100\n",
            "The dataset size reduced from 7500 to 7500\n",
            "time taken for clustering and pruning: 0:00:01.622844\n",
            "time taken for fpgrowth with clustering: 0:00:00.492611\n",
            "Time taken by fpgrowth without clustering :0:00:00.369698\n",
            "\n",
            "\n",
            "for min_sup = 200\n",
            "The dataset size reduced from 7500 to 7450\n",
            "time taken for clustering and pruning: 0:00:01.612014\n",
            "time taken for fpgrowth with clustering: 0:00:00.245513\n",
            "Time taken by fpgrowth without clustering :0:00:00.270924\n",
            "\n",
            "\n",
            "for min_sup = 300\n",
            "The dataset size reduced from 7500 to 7338\n",
            "time taken for clustering and pruning: 0:00:01.672205\n",
            "time taken for fpgrowth with clustering: 0:00:00.341644\n",
            "Time taken by fpgrowth without clustering :0:00:00.191653\n",
            "\n",
            "\n",
            "for min_sup = 400\n",
            "The dataset size reduced from 7500 to 7127\n",
            "time taken for clustering and pruning: 0:00:01.604644\n",
            "time taken for fpgrowth with clustering: 0:00:00.122998\n",
            "Time taken by fpgrowth without clustering :0:00:00.133322\n",
            "\n",
            "\n",
            "for min_sup = 500\n",
            "The dataset size reduced from 7500 to 6832\n",
            "time taken for clustering and pruning: 0:00:01.604087\n",
            "time taken for fpgrowth with clustering: 0:00:00.058439\n",
            "Time taken by fpgrowth without clustering :0:00:00.080740\n",
            "\n",
            "\n",
            "for min_sup = 600\n",
            "The dataset size reduced from 7500 to 6543\n",
            "time taken for clustering and pruning: 0:00:01.651985\n",
            "time taken for fpgrowth with clustering: 0:00:00.050099\n",
            "Time taken by fpgrowth without clustering :0:00:00.051021\n",
            "\n",
            "\n",
            "for min_sup = 700\n",
            "The dataset size reduced from 7500 to 6131\n",
            "time taken for clustering and pruning: 0:00:01.653153\n",
            "time taken for fpgrowth with clustering: 0:00:00.023158\n",
            "Time taken by fpgrowth without clustering :0:00:00.039818\n",
            "\n",
            "\n",
            "for min_sup = 800\n",
            "The dataset size reduced from 7500 to 5984\n",
            "time taken for clustering and pruning: 0:00:01.612073\n",
            "time taken for fpgrowth with clustering: 0:00:00.024715\n",
            "Time taken by fpgrowth without clustering :0:00:00.030681\n",
            "\n",
            "\n",
            "for min_sup = 900\n",
            "The dataset size reduced from 7500 to 5610\n",
            "time taken for clustering and pruning: 0:00:01.642611\n",
            "time taken for fpgrowth with clustering: 0:00:00.021000\n",
            "Time taken by fpgrowth without clustering :0:00:00.029122\n",
            "\n",
            "\n",
            "for min_sup = 1000\n",
            "The dataset size reduced from 7500 to 5332\n",
            "time taken for clustering and pruning: 0:00:01.636075\n",
            "time taken for fpgrowth with clustering: 0:00:00.017320\n",
            "Time taken by fpgrowth without clustering :0:00:00.027045\n",
            "\n",
            "\n",
            "for min_sup = 1100\n",
            "The dataset size reduced from 7500 to 4873\n",
            "time taken for clustering and pruning: 0:00:01.613101\n",
            "time taken for fpgrowth with clustering: 0:00:00.015370\n",
            "Time taken by fpgrowth without clustering :0:00:00.026094\n",
            "\n",
            "\n",
            "for min_sup = 1200\n",
            "The dataset size reduced from 7500 to 4759\n",
            "time taken for clustering and pruning: 0:00:01.649755\n",
            "time taken for fpgrowth with clustering: 0:00:00.010446\n",
            "Time taken by fpgrowth without clustering :0:00:00.026703\n",
            "\n",
            "\n",
            "for min_sup = 1300\n",
            "The dataset size reduced from 7500 to 4697\n",
            "time taken for clustering and pruning: 0:00:01.659236\n",
            "time taken for fpgrowth with clustering: 0:00:00.011270\n",
            "Time taken by fpgrowth without clustering :0:00:00.020490\n",
            "\n",
            "\n",
            "for min_sup = 1400\n",
            "The dataset size reduced from 7500 to 4630\n",
            "time taken for clustering and pruning: 0:00:01.646288\n",
            "time taken for fpgrowth with clustering: 0:00:00.008600\n",
            "Time taken by fpgrowth without clustering :0:00:00.015110\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy7NpbsPZKwa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}